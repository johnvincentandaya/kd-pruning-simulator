from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import torch.nn.utils.prune as prune
from transformers import BertForSequenceClassification, BertTokenizer, DistilBertForSequenceClassification
from werkzeug.utils import secure_filename
import os
from flask_socketio import SocketIO, emit  # Ensure emit is imported
import time
import pandas as pd
from torch.utils.data import Dataset

app = Flask(__name__)  # âœ… Define app before using it in SocketIO
CORS(app, resources={r"/*": {"origins": "*"}})  # Fix CORS for all routes
socketio = SocketIO(app, cors_allowed_origins="*")  # Ensure CORS is allowed for SocketIO

UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config["UPLOAD_FOLDER"] = UPLOAD_FOLDER

# Initialize Models
teacher_model = BertForSequenceClassification.from_pretrained("bert-base-uncased")
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
student_model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")

# Add a flag to track if the model has been trained
model_trained = False

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({"success": False, "error": "No file uploaded"}), 400

    file = request.files['file']
    if file.filename == "":
        return jsonify({"success": False, "error": "No selected file"}), 400

    allowed_extensions = {".csv", ".json", ".txt", ".xlsx", ".jpg", ".png", ".zip"}
    file_ext = os.path.splitext(file.filename)[1].lower()
    if file_ext not in allowed_extensions:
        return jsonify({"success": False, "error": f"Unsupported file type: {file_ext}"}), 400

    filename = secure_filename(file.filename)
    file_path = os.path.join(app.config["UPLOAD_FOLDER"], filename)
    file.save(file_path)

    return jsonify({"success": True, "message": "File uploaded successfully", "filename": filename, "file_path": file_path})

@app.route('/train', methods=['POST'])
def train_model():
    global model_trained, student_model

    uploaded_file = request.json.get("file_path")
    print(f"Received file path: {uploaded_file}")  # Debug print

    if not uploaded_file or not os.path.exists(uploaded_file):
        return jsonify({"success": False, "error": "Uploaded file not found"}), 400

    try:
        # Simulate training progress for testing
        total_steps = 10
        for step in range(total_steps + 1):
            progress = int((step / total_steps) * 100)
            print(f"Emitting progress: {progress}%")  # Debug print
            socketio.emit('training_progress', {'progress': progress})
            time.sleep(1)  # Simulate training time

        model_trained = True
        return jsonify({"success": True, "message": "Training completed successfully!"})
    
    except Exception as e:
        print(f"Error during training: {e}")  # Debug print
        return jsonify({"success": False, "error": str(e)}), 500

def evaluate_trained_model(model, data):
    # Mock evaluation for testing
    return 85.5, 82.3, 84.1  # accuracy, precision, recall

def get_model_size(model):
    # Calculate model size in MB
    param_size = 0
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
    return param_size / (1024 * 1024)  # Convert to MB

def get_model_structure(model):
    """Extract the neural network structure for visualization."""
    nodes = []
    connections = []
    layer_spacing = 2
    nodes_per_layer = 8  # Simplified representation

    # Extract layers from the model
    layers = [module for module in model.modules() if not list(module.children())]
    
    # Create nodes
    for layer_idx, layer in enumerate(layers):
        for node_idx in range(nodes_per_layer):
            x = layer_idx * layer_spacing
            y = (node_idx - nodes_per_layer/2) * 0.5
            z = 0
            
            node = {
                "id": f"layer{layer_idx}_node{node_idx}",
                "x": float(x),
                "y": float(y),
                "z": float(z),
                "size": 0.2,
                "color": "#00ff00" if layer_idx == 0 else "#0000ff" if layer_idx == len(layers)-1 else "#ffff00"
            }
            nodes.append(node)

            # Create connections to previous layer
            if layer_idx > 0:
                for prev_node in range(nodes_per_layer):
                    if node_idx % 2 == prev_node % 2:  # Simplified connectivity pattern
                        connection = {
                            "source": {
                                "x": float((layer_idx-1) * layer_spacing),
                                "y": float((prev_node - nodes_per_layer/2) * 0.5),
                                "z": 0
                            },
                            "target": {
                                "x": float(x),
                                "y": float(y),
                                "z": float(z)
                            },
                            "strength": 0.8  # Connection strength (can be based on weights)
                        }
                        connections.append(connection)

    return {
        "nodes": nodes,
        "connections": connections,
        "metadata": {
            "total_layers": len(layers),
            "nodes_per_layer": nodes_per_layer,
            "model_type": "DistilBERT"
        }
    }

@app.route('/evaluate', methods=['POST'])
def evaluate_model():
    global model_trained, student_model

    if not model_trained:
        return jsonify({"success": False, "error": "Model has not been trained yet"}), 400

    try:
        accuracy, precision, recall = evaluate_trained_model(student_model, None)
        
        evaluation_results = [
            {"metric": "Model Accuracy", "value": f"{accuracy:.2f}%"},
            {"metric": "Precision", "value": f"{precision:.2f}%"},
            {"metric": "Recall", "value": f"{recall:.2f}%"},
        ]
        
        return jsonify({"success": True, "message": "Evaluation completed!", "results": evaluation_results})
    except Exception as e:
        print(f"Evaluation error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/visualize', methods=['POST'])
def visualize_model():
    global student_model, model_trained

    if not model_trained:
        return jsonify({"success": False, "error": "Model must be trained first"}), 400

    try:
        # Generate actual model structure
        model_structure = get_model_structure(student_model)
        
        return jsonify({
            "success": True,
            "data": model_structure,
            "message": "Model structure generated successfully"
        })
    except Exception as e:
        print(f"Visualization error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/distill', methods=['POST'])
def distill_model():
    global teacher_model, student_model, model_trained

    if not model_trained:
        return jsonify({"success": False, "error": "Model has not been trained yet"}), 400

    try:
        # Get actual metrics
        teacher_size = get_model_size(teacher_model)
        student_size = get_model_size(student_model)
        
        teacher_acc, _, _ = evaluate_trained_model(teacher_model, None)
        student_acc, _, _ = evaluate_trained_model(student_model, None)

        distillation_metrics = [
            {"metric": "Teacher Accuracy", "value": f"{teacher_acc:.2f}%"},
            {"metric": "Student Accuracy", "value": f"{student_acc:.2f}%"},
            {"metric": "Size Reduction", "value": f"{(teacher_size/student_size):.1f}x"},
            {"metric": "Memory Saved", "value": f"{(teacher_size - student_size):.1f}MB"}
        ]
        
        return jsonify({"success": True, "results": distillation_metrics})
    except Exception as e:
        print(f"Distillation error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/prune', methods=['POST'])
def prune_model():
    global student_model, model_trained

    if not model_trained:
        return jsonify({"success": False, "error": "Model has not been trained yet"}), 400

    try:
        original_size = get_model_size(student_model)
        original_acc, _, _ = evaluate_trained_model(student_model, None)

        # Simulate pruning effects
        pruned_size = original_size * 0.7  # 30% reduction
        pruned_acc = original_acc * 0.98  # 2% accuracy loss

        pruning_metrics = [
            {"metric": "Original Size", "value": f"{original_size:.1f}MB"},
            {"metric": "Pruned Size", "value": f"{pruned_size:.1f}MB"},
            {"metric": "Size Reduction", "value": f"{((original_size-pruned_size)/original_size*100):.1f}%"},
            {"metric": "Accuracy Impact", "value": f"-{(original_acc-pruned_acc):.1f}%"}
        ]
        
        return jsonify({"success": True, "results": pruning_metrics})
    except Exception as e:
        print(f"Pruning error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

if __name__ == '__main__':
    socketio.run(app, debug=True, host="0.0.0.0", port=5000)  # Ensure the server is accessible
